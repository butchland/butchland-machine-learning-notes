<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://butchland.github.io/butchland-machine-learning-notes/feed.xml" rel="self" type="application/atom+xml" /><link href="https://butchland.github.io/butchland-machine-learning-notes/" rel="alternate" type="text/html" /><updated>2020-06-26T10:40:54-05:00</updated><id>https://butchland.github.io/butchland-machine-learning-notes/feed.xml</id><title type="html">Butch Landingin’s Machine Learning Notes</title><subtitle>My explorations in machine learning</subtitle><entry><title type="html">Fastbook Chapter 1 Introduction</title><link href="https://butchland.github.io/butchland-machine-learning-notes/fastai/2020/06/22/fastbook-chapter-1-introduction.html" rel="alternate" type="text/html" title="Fastbook Chapter 1 Introduction" /><published>2020-06-22T00:00:00-05:00</published><updated>2020-06-22T00:00:00-05:00</updated><id>https://butchland.github.io/butchland-machine-learning-notes/fastai/2020/06/22/fastbook-chapter-1-introduction</id><content type="html" xml:base="https://butchland.github.io/butchland-machine-learning-notes/fastai/2020/06/22/fastbook-chapter-1-introduction.html">&lt;p&gt;&lt;em&gt;These are my notes from my reading of the fastai book&lt;/em&gt;
&lt;em&gt;by Jeremy Howard and Sylvain Gugger&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/00-00-49-fastbook.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;your-deep-learning-journey&quot;&gt;Your Deep Learning Journey&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Deep Learning is for Everyone&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Deep Learning (DL)&lt;/strong&gt;  is a powerful tool that uses data to build powerful applications that would otherwise have been impossible to build using normal programming techniques.
    &lt;ul&gt;
      &lt;li&gt;Can be applied across many disciplines&lt;/li&gt;
      &lt;li&gt;Domain experts can find new applications for it&lt;/li&gt;
      &lt;li&gt;Need more people with different backgrounds to get involved and start using it&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.fast.ai/&quot;&gt;fast.ai&lt;/a&gt; was founded to spread DL into the hands of as many people as possible&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Accessibility:&lt;/strong&gt; DL is a technology that is accessible to normal folks. You don’t need:
    &lt;ul&gt;
      &lt;li&gt;lots of math&lt;/li&gt;
      &lt;li&gt;lots of data&lt;/li&gt;
      &lt;li&gt;lots of expensive computers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/00-06-41-what-you-dont-need-in-dl.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: high school math, some coding experience required preferably Python
    &lt;ul&gt;
      &lt;li&gt;but Python is easy to learn, lots of &lt;a href=&quot;https://www.learnpython.org/&quot;&gt;free online courses&lt;/a&gt; teach it.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Why learn DL?&lt;/strong&gt;  - Areas/Fields/Disciplines where DL is now best in the world:
    &lt;ul&gt;
      &lt;li&gt;Natural Language Processing (NLP)&lt;/li&gt;
      &lt;li&gt;Computer Vision (CV)&lt;/li&gt;
      &lt;li&gt;Medicine&lt;/li&gt;
      &lt;li&gt;Biology&lt;/li&gt;
      &lt;li&gt;Image Generation&lt;/li&gt;
      &lt;li&gt;Recommendation Systems&lt;/li&gt;
      &lt;li&gt;Playing Games&lt;/li&gt;
      &lt;li&gt;Robotics&lt;/li&gt;
      &lt;li&gt;Others&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/00-08-41-dl-sota-areas.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;neural-networks-a-brief-history&quot;&gt;Neural Networks: A Brief History&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/00-10-08-neural-networks-rosenblatt.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Warren McCulloch and Walter Pitts, 1943&lt;/strong&gt; - developed mathematical model of artificial neuron&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Frank Rosenblatt,&lt;/strong&gt; gave the artificial neural network (NN) the ability to learn, and built the &lt;em&gt;Mark 1 Perceptron&lt;/em&gt;, a machine capable of recognizing simple shapes&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Marvin Minsky &amp;amp; Seymour Papert&lt;/strong&gt; wrote &lt;em&gt;Perceptrons&lt;/em&gt; (book)
    &lt;ul&gt;
      &lt;li&gt;asserted that NNs are limited
        &lt;ul&gt;
          &lt;li&gt;1 layer NNs can’t even compute XOR&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;but also asserted 2 layers can compute more complex functions
        &lt;ul&gt;
          &lt;li&gt;this was kind of disregarded, instead people focused only on the 1st assertion&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;as a result, research on NNs was almost non-existent in the next 2 decades
        &lt;ul&gt;
          &lt;li&gt;led to first AI winter&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In 1986, MIT published the 2 volume book &lt;strong&gt;Parallel Distributed Processing (PDP)&lt;/strong&gt;,  where it asserts that a NN-based system requires:
    &lt;ul&gt;
      &lt;li&gt;processing units&lt;/li&gt;
      &lt;li&gt;activation state&lt;/li&gt;
      &lt;li&gt;output function&lt;/li&gt;
      &lt;li&gt;pattern of connectivity&lt;/li&gt;
      &lt;li&gt;propagation rule&lt;/li&gt;
      &lt;li&gt;activation rule&lt;/li&gt;
      &lt;li&gt;learning rule&lt;/li&gt;
      &lt;li&gt;environment&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/00-10-38-pdp-pipeline.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;80’s and 90s -&lt;/strong&gt; 2 layer NN began to widely used for real practical projects. but were too big or to slow&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;90s&lt;/strong&gt; researchers showed that more layers needed to get practical good performance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;last decade&lt;/strong&gt; - increases in data availability, improvements in hardware, algorithmic tweaks made deep neural networks practical and powerful.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;who-we-are&quot;&gt;Who We Are&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Jeremy, Sylvain, Rachel
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.fast.ai/about/#founders&quot;&gt;About FastAI Team&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://www.fast.ai/images/jh-head.jpg&quot; alt=&quot;headpic&quot; title=&quot;Jeremy Howard&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.fast.ai/images/thomas.JPG&quot; alt=&quot;headpic&quot; title=&quot;Rachel Thomas&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.fast.ai/images/sg-head.jpg&quot; alt=&quot;headpic&quot; title=&quot;Sylvain Gugger&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-to-learn-dl&quot;&gt;How to learn DL&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Based on work by David Perkins, “Making Learning Whole”
    &lt;ul&gt;
      &lt;li&gt;learn the whole game&lt;/li&gt;
      &lt;li&gt;learn through examples&lt;/li&gt;
      &lt;li&gt;simplify as much as possible&lt;/li&gt;
      &lt;li&gt;remove barriers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/00-16-38-play-whole-game.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Code and try to solve problems - theory can come later.&lt;/li&gt;
  &lt;li&gt;Much of deep learning is still artisanal and can only be learned by actual experience in building models and datasets.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tenacity is key&lt;/strong&gt; - getting stuck is normal. rewind and read slowly if stuck, experiment and google.&lt;/li&gt;
  &lt;li&gt;Apply to personal projects so you can sustain interest&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;projects-and-mindset&quot;&gt;Projects and Mindset&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Get good test cases and projects&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;focus on hobbies and passion&lt;/li&gt;
      &lt;li&gt;try something not to ambitious at first, so that you don’t get stuck.&lt;/li&gt;
      &lt;li&gt;set 4 or 5 little projects instead of 1 grand project.&lt;/li&gt;
      &lt;li&gt;once you’ve done some little projects, go for bigger project you can show off.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Character traits for success&lt;/strong&gt;: playfulness and curiosity.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-software-stack-pytorch-fastai-jupyter&quot;&gt;The Software Stack: Pytorch, fastai, Jupyter&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/00-23-35-fastai-pytorch.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Pytorch&lt;/strong&gt; &lt;a href=&quot;https://pytorch.org&quot;&gt;provides&lt;/a&gt; low level foundation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;fastai&lt;/strong&gt; &lt;a href=&quot;https://dev.fast.ai&quot;&gt;provides&lt;/a&gt; higher level abstractions and productivity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/00-25-57-fastai-paper.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Jupyter notebook&lt;/strong&gt; - &lt;a href=&quot;https://jupyter.org/&quot;&gt;provides&lt;/a&gt; the experimentation and documentation environment&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;first-model&quot;&gt;First Model&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Setup your GPU DL Server
    &lt;ul&gt;
      &lt;li&gt;use Cloud (e.g. &lt;a href=&quot;https://colab.research.google.com&quot;&gt;Colab&lt;/a&gt; or &lt;a href=&quot;https://gradient.paperspace.com/&quot;&gt;Paperspace&lt;/a&gt;)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Run your first notebook
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/fastai/course-v4&quot;&gt;Course notebooks site&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://book.fast.ai&quot;&gt;Book site&lt;/a&gt; and &lt;a href=&quot;https://github.com/fastai/fastbook&quot;&gt;book notebooks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;setup account (gmail for colab, email for paperspace)
        &lt;ul&gt;
          &lt;li&gt;for paperspace - see &lt;a href=&quot;https://course.fast.ai/start_gradient.html&quot;&gt;paperspace setup&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;for colab - see &lt;a href=&quot;https://course.fast.ai/start_colab.html&quot;&gt;colab setup&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;load notebooks
        &lt;ul&gt;
          &lt;li&gt;for colab
            &lt;ul&gt;
              &lt;li&gt;modify notebook for colab environment - see &lt;a href=&quot;https://forums.fast.ai/t/platform-colab-free-10-month-pro/65525&quot;&gt;forum post&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;setup google drive to clone course notebooks&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;view &lt;a href=&quot;https://github.com/fastai/course-v4/blob/master/nbs/app_jupyter.ipynb&quot;&gt;app_jupyter.ipynb&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;run &lt;a href=&quot;https://github.com/fastai/course-v4/blob/master/nbs/01_intro.ipynb&quot;&gt;first notebook&lt;/a&gt;: Cats and Dogs Image Classifier
        &lt;ul&gt;
          &lt;li&gt;duplicate and save notebook&lt;/li&gt;
          &lt;li&gt;get dataset, create dataloader, create learner, train model&lt;/li&gt;
          &lt;li&gt;do inference on model&lt;/li&gt;
          &lt;li&gt;build image uploader and run inference on uploader using trained model: &lt;em&gt;is this a cat?&lt;/em&gt;
            &lt;ul&gt;
              &lt;li&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/cute-kitty.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-is-machine-learning-ml&quot;&gt;What is Machine Learning (ML)&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Deep learning is a modern area in the general discipline of ML&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Normal Programs&lt;/strong&gt; - make computer do a task by giving it detailed instructions
    &lt;ul&gt;
      &lt;li&gt;inputs → program → outputs&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/programs.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ML is an ALTERNATIVE way to get computers to do a task by giving it examples&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Arthur Samuels formulation (IBM, 1949) - 1962 essay - &lt;em&gt;AI: A frontier of automation:&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;weights&lt;/strong&gt; are assigned
        &lt;ul&gt;
          &lt;li&gt;weights are variables - given a particular choice of values&lt;/li&gt;
          &lt;li&gt;inputs are values processed to produce results,&lt;/li&gt;
          &lt;li&gt;weights are other values that define how the program will operate.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;every weight assignment &lt;strong&gt;results&lt;/strong&gt; in some level of &lt;strong&gt;performance&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;automated means of &lt;strong&gt;measuring performance&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;mechanism for &lt;strong&gt;improving performance&lt;/strong&gt; by weight assignments&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Training Models&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;inputs + weights → model → outputs + labels → performance → (update) → weights&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/trainmodels2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;using modern terms&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/trainmodels3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cat Dog Image Recognition Example
    &lt;ul&gt;
      &lt;li&gt;inputs  -&amp;gt; images of cats and dogs&lt;/li&gt;
      &lt;li&gt;parameters -&amp;gt; “weights”&lt;/li&gt;
      &lt;li&gt;outputs -&amp;gt; predict whether its a cat or dog&lt;/li&gt;
      &lt;li&gt;label -&amp;gt; actual value whether image is a cat or dog&lt;/li&gt;
      &lt;li&gt;loss - if output matches label -&amp;gt; loss is low, if output does not match label -&amp;gt; loss is high&lt;/li&gt;
      &lt;li&gt;after measuring loss, update the parameters using SGD&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Inference (after training)
    &lt;ul&gt;
      &lt;li&gt;inputs + weights (now part of model) → outputs&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/trainmodels.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-is-a-neural-network-nn&quot;&gt;What is a Neural Network (NN)?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;A function that can compute any set of outputs given a set of inputs&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Universal Approximation Theorem&lt;/strong&gt; - &lt;a href=&quot;https://en.wikipedia.org/wiki/Universal_approximation_theorem&quot;&gt;shows&lt;/a&gt; that neural networks can solve any problem to any level of accuracy.&lt;/li&gt;
  &lt;li&gt;To find a way to update the “weights”  of a NN in order to improve its performance, we use &lt;strong&gt;Stochastic Gradient Descent (&lt;/strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;&gt;SGD&lt;/a&gt;&lt;strong&gt;)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-learning-jargon&quot;&gt;Deep Learning Jargon&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Architecture&lt;/em&gt; - functional form of the model&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Parameters&lt;/em&gt; - “weights” that form the model&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Predictions&lt;/em&gt; are calculated from the &lt;em&gt;independent variables&lt;/em&gt;, which is the &lt;em&gt;input data&lt;/em&gt; not including the &lt;em&gt;labels&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Outputs&lt;/em&gt; of the model given its &lt;em&gt;inputs&lt;/em&gt; (which are the &lt;em&gt;independent variables&lt;/em&gt;) are called &lt;em&gt;predictions *and are also considered the *dependent variables&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;The measure of &lt;em&gt;performance&lt;/em&gt; is called the &lt;em&gt;loss&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Loss&lt;/em&gt; is dependent on the &lt;em&gt;predictions&lt;/em&gt; plus the correct &lt;em&gt;labels&lt;/em&gt; aka &lt;em&gt;targets&lt;/em&gt; or &lt;em&gt;dependent variables&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;inputs + parameters → model architecture → predictions (outputs) + labels → loss → (update) parameters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/trainmodels3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;limitations-inherent-in-ml&quot;&gt;Limitations inherent in ML&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;A model cannot be created without data&lt;/li&gt;
  &lt;li&gt;A model can only learn to operate on patterns seen in the input data used to train it&lt;/li&gt;
  &lt;li&gt;The learning approach creates &lt;em&gt;predictions&lt;/em&gt; not recommended actions&lt;/li&gt;
  &lt;li&gt;It is not enough to have examples of input data, we also need the &lt;em&gt;labels&lt;/em&gt; for the input data&lt;/li&gt;
  &lt;li&gt;Need to think about how ML is applied since its predictions are sometimes used for recommendation systems that can predict what a user is most likely to do.&lt;/li&gt;
  &lt;li&gt;Also need to think about the &lt;em&gt;environment&lt;/em&gt; where ML is applied and how it interacts with the environment it is getting its data from.
    &lt;ul&gt;
      &lt;li&gt;example : recommender systems creating feedback loops
        &lt;ul&gt;
          &lt;li&gt;predictive policing model - amplifies existing racial bias in policing by predicting more crime in areas where POC are dominant and recommends more policing in those areas, leading to more arrests — arrests proxy for crime, so data (and models based on the data) will lead to a positive feedback loop.&lt;/li&gt;
          &lt;li&gt;youtube videos recommending more extremist views to increase engagement — since videos with extremist views tend to be more engaging, system recommends those videos, leading viewers to espouse more extremist views and encouraging them to engage more with those types of extremist videos.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-the-image-recognizer-works&quot;&gt;How the Image Recognizer works&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Model Training&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;Code sample&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from fastai2.vision.all import *

path = untar_data(URLs.PETS)

def is_cat(item): return item.name[0].isupper()

dls = ImageDataLoaders.from_name_func(path, get_image_files(path),
          label_func=is_cat,item_tfms=Resize(224),valid_pct=0.2, 
          seed=42)
learn = cnn_learner(dls,resnet34, metrics=error_rate)
learn.fine_tune(1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;from fastai2.vision.all import * :&lt;/code&gt; import fastai library  - fastai2.vision.all package contains all the needed functions&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;path = untar_data(URLs.PETS)&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt; download data from a URL&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;def is_cat(item)...:&lt;/code&gt; define function to determine label based on filename
    &lt;ul&gt;
      &lt;li&gt;for the PETS dataset, if the name of the file is capitalized, its a cat, otherwise its a dog&lt;/li&gt;
      &lt;li&gt;the type of the output or label determines the type of ML problem:
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;regression&lt;/strong&gt; - when output is continuous value&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;classification&lt;/strong&gt; - when output is a discrete set of values&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dls = ImageDataLoaders.from_name_func...&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt; defines how to load data that will be fed to the model using a &lt;em&gt;dataloader&lt;/em&gt; object
    &lt;ul&gt;
      &lt;li&gt;what type of data is input (&lt;em&gt;Image&lt;/em&gt;)&lt;/li&gt;
      &lt;li&gt;what output is expected (&lt;code class=&quot;highlighter-rouge&quot;&gt;label_func=is_cat&lt;/code&gt; to determine target label)&lt;/li&gt;
      &lt;li&gt;what transforms need to be applied to input data.
        &lt;ul&gt;
          &lt;li&gt;item transforms - applied to each item (&lt;code class=&quot;highlighter-rouge&quot;&gt;Resize(224)&lt;/code&gt;)
            &lt;ul&gt;
              &lt;li&gt;224 is standard for historical reasons (pretrained model used 224x224 as image size)&lt;/li&gt;
              &lt;li&gt;can increase size for better detail and possibly better results, but more resource intensive, reducing size reduces detail, but can run much faster with less memory&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;batch transforms - applied to a batch of items (typically on GPU so its fast)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;split &lt;em&gt;validation&lt;/em&gt; from &lt;em&gt;training&lt;/em&gt; sets - by default 20% of input is randomly selected as validation with a set &lt;code class=&quot;highlighter-rouge&quot;&gt;seed=42&lt;/code&gt; (to fix the splitting)
        &lt;ul&gt;
          &lt;li&gt;&lt;em&gt;why split into training and validation sets?&lt;/em&gt;
            &lt;ul&gt;
              &lt;li&gt;NNs can “memorize” the training data, which will make model predict well with data used in training, but will not generalize to other data not used in training.&lt;/li&gt;
              &lt;li&gt;By setting aside data in a validation set, this data in the validation set is not used in training, but is used to monitor &lt;em&gt;overfitting&lt;/em&gt;.&lt;/li&gt;
              &lt;li&gt;&lt;strong&gt;Overfitting&lt;/strong&gt; occurs when NN is optimizing on training data but performance on validation set is worsening.
                &lt;ul&gt;
                  &lt;li&gt;&lt;strong&gt;Overfitting&lt;/strong&gt; is one of the most important and challenging issue in ML&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;learn = cnn_learner(..&lt;/code&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt; create cnn learner with architecture and metrics using dataloader
    &lt;ul&gt;
      &lt;li&gt;set &lt;em&gt;validation metrics&lt;/em&gt; to show model performance and monitor &lt;strong&gt;overfitting&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;Metrics&lt;/strong&gt; is different from &lt;strong&gt;loss&lt;/strong&gt; - metrics measure &lt;em&gt;quality&lt;/em&gt; of model predictions, loss is used for tracking how the &lt;em&gt;performance&lt;/em&gt; changes as model parameters are changed (used in training)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;set the &lt;em&gt;architecture&lt;/em&gt; - in our case &lt;code class=&quot;highlighter-rouge&quot;&gt;resnet34&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;different architectures available
        &lt;ul&gt;
          &lt;li&gt;example &lt;em&gt;resnet34&lt;/em&gt; comes with 34 layers, &lt;em&gt;resnet50&lt;/em&gt; with 50, &lt;em&gt;resnet152&lt;/em&gt; with 152 layers, etc
            &lt;ul&gt;
              &lt;li&gt;visualize the NN as consisting of layered cake - with the inputs (images) entering from the bottom and the predictions coming out from the top (aka the head)…&lt;/li&gt;
              &lt;li&gt;NN with 50 and 152 layers are bigger than one with 34 layers, resnet18 is the smallest in the resnet family.&lt;/li&gt;
              &lt;li&gt;smaller NNs are faster to train, larger NNs are more powerful in capturing nuances (in general)&lt;/li&gt;
              &lt;li&gt;to find the ideal size, you have to experiment - but resnet34 is usually a good compromise and default&lt;/li&gt;
              &lt;li&gt;there are also other families and variations within familities of architectures&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;pretrained flag - default to true&lt;/strong&gt; - use pretrained weights - where a model trained in a different related task is reused for another task, reducing the amount of training time and data needed to achieve good performance.
    &lt;ul&gt;
      &lt;li&gt;pretrained will remove the last (topmost) layer and replace with 1 or more randomised layers specific for your task.&lt;/li&gt;
      &lt;li&gt;using a pretrained model is &lt;strong&gt;the most important method&lt;/strong&gt; to allow us to train accurate models, more quickly with less data and less time and money.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transfer learning&lt;/strong&gt; - using a pretrained model for a task different from what it was trained for. 
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Most important technique&lt;/strong&gt; to reduce resources (data, compute, time) needed to train models to acceptable or even state of the art (SOTA) performance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;learn.fine_tune(1)&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt; fit (i.e. train)  the model to your task.
    &lt;ul&gt;
      &lt;li&gt;1 is the number of epochs - the number of times your model looks at each sample of input data.&lt;/li&gt;
      &lt;li&gt;there is also a &lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt; method that does fit the model, but &lt;code class=&quot;highlighter-rouge&quot;&gt;fine_tune&lt;/code&gt; does additional “tricks” to adapt a pretrained model for a new dataset, a process known as &lt;em&gt;fine tuning&lt;/em&gt;.
        &lt;ul&gt;
          &lt;li&gt;fine tune - 1. use one epoch (aka freeze_epochs parameter defaulted to 1) - to train just the head, with the rest of the model frozen&lt;/li&gt;
          &lt;li&gt;unfreeze the lower layers, and train using the &lt;em&gt;discriminative learning rates&lt;/em&gt;, where the lower layers (which need less adjustments since it has already been pretrained) are trained with lower learning rate, the &lt;em&gt;head&lt;/em&gt; (which starts with random values) is trained with higher rates
            &lt;ul&gt;
              &lt;li&gt;the &lt;em&gt;learning rate&lt;/em&gt; is a “&lt;em&gt;hyperparameter&lt;/em&gt;” - a knob that is used to tweak the training of the model in order to make the model achieve a better level of performance faster.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-our-image-recognizer-learned&quot;&gt;What our Image Recognizer Learned&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;the model might be performing well, but its still a “black box” as to what its really doing (this is a known problem in ML).&lt;/li&gt;
  &lt;li&gt;there are techniques to inspect DL models and get insights, but it can be challenging to understand, especially when they encounter data that is very different from the one used in training the model.&lt;/li&gt;
  &lt;li&gt;Zeiler and Fergus, 2013 - &lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;Visualizing and Understanding CNNs&lt;/a&gt; - visualization of NN weights learned in each layer.
    &lt;ul&gt;
      &lt;li&gt;lower layers - simple shapes&lt;/li&gt;
      &lt;li&gt;higher layers - more complex shapes combined from lower layers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/layer1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/layer2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/chapter2_layer3.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/chapter2_layer4and5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The model (Alexnet) studied had only 5 layers so deeper networks even can recognize even more complex features.
The upper layers (ie. the head) are specialized for the task specific to your model (distinguishing cats from dogs) and so require higher learning rates compared to lower layers which share more or less the same features as the pretrained model.&lt;/p&gt;

&lt;h2 id=&quot;extending-image-recognizers-to-handle-non-image-tasks&quot;&gt;Extending Image Recognizers to handle Non-Image Tasks&lt;/h2&gt;

&lt;p&gt;One way to extend image recognizers is by converting data into images which can then reuse pretrained image models.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sound - converted to spectograms - see this &lt;a href=&quot;https://medium.com/@etown/great-results-on-audio-classification-with-fastai-library-ccaf906c5f52&quot;&gt;article&lt;/a&gt; using fastai for audio classification&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/att_00012.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mouse movements - Splunk converted recorded mouse movements into images which were then used to train a bot detector - &lt;a href=&quot;https://www.splunk.com/en_us/blog/security/deep-learning-with-splunk-and-tensorflow-for-security-catching-the-fraudster-in-neural-networks-with-behavioral-biometrics.html&quot;&gt;see this article&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/att_00014.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;General tip:&lt;/strong&gt; if your data can be converted to image data and the images can be classified by humans looking at the images, chances are image recognizers using transfer learning can be trained to classify them as well.&lt;/p&gt;

&lt;h2 id=&quot;more-jargon&quot;&gt;More Jargon&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Label&lt;/li&gt;
  &lt;li&gt;Architecture&lt;/li&gt;
  &lt;li&gt;Model&lt;/li&gt;
  &lt;li&gt;Parameters&lt;/li&gt;
  &lt;li&gt;Fit&lt;/li&gt;
  &lt;li&gt;Train&lt;/li&gt;
  &lt;li&gt;Pretrained Model&lt;/li&gt;
  &lt;li&gt;Fine tuning&lt;/li&gt;
  &lt;li&gt;Epoch&lt;/li&gt;
  &lt;li&gt;Loss&lt;/li&gt;
  &lt;li&gt;Metric&lt;/li&gt;
  &lt;li&gt;Generalization&lt;/li&gt;
  &lt;li&gt;Overfitting&lt;/li&gt;
  &lt;li&gt;Training Set&lt;/li&gt;
  &lt;li&gt;Validation Sets&lt;/li&gt;
  &lt;li&gt;Convolutional NNs&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;other-applications-of-dl&quot;&gt;Other applications of DL&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Image Segmentation&lt;/strong&gt; - label each pixel with object it belongs to
    &lt;ul&gt;
      &lt;li&gt;CamVid example using subset of data from the paper &lt;a href=&quot;http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/&quot;&gt;Semantic Object Classes in Video: A High-Definition Ground Truth Database&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/dlcp_01in03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Sentiment Classification&lt;/strong&gt; (Natural Language Processing or NLP) - tells you if movie review is positive or negative
    &lt;ul&gt;
      &lt;li&gt;Movie Review Sentiment Classification using IMDB data from the paper &lt;a href=&quot;https://ai.stanford.edu/~amaas/data/sentiment/&quot;&gt;Learning Word Vectors for Sentiment Analysis&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tabular Data&lt;/strong&gt; - predicts income based on multiple factors such as age, educational attainment etc.
    &lt;ul&gt;
      &lt;li&gt;Income prediction using &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/adult&quot;&gt;Adult dataset&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Recommendation Systems&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Movie Recommendation using &lt;a href=&quot;https://doi.org/10.1145/2827872&quot;&gt;movie lens dataset&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;validation-sets-and-test-sets&quot;&gt;Validation Sets and Test Sets&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;train set&lt;/strong&gt; - data seen by model during training&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;validation set&lt;/strong&gt; - used for evaluating model - test model to generalize and tweak it appropriately (hyper parameter tuning)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;test set&lt;/strong&gt; - data reserved for predicting performance in the real world (after tweaking)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TIP&lt;/strong&gt; for creating validation and test sets - simulate data that will be encountered in production - random subsets may not always be best way to select validation - e.g. time series data - should use continuous data in the future w.r.t. to data used or images not in training data (assuming they occur multiple times)&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">These are my notes from my reading of the fastai book by Jeremy Howard and Sylvain Gugger</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://butchland.github.io/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/00-00-49-fastbook.png" /><media:content medium="image" url="https://butchland.github.io/butchland-machine-learning-notes/assets/images/Fastbook_Chapter_1_Introduction_files/FastAI2020/Lesson_1_Introduction/Fastbook_Chapter_1_Introduction/00-00-49-fastbook.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Fastbook Chapter 2 Questionnaire Answers</title><link href="https://butchland.github.io/butchland-machine-learning-notes/fastai/2020/06/02/fast-ai-chapter-2-prod-questionnaire-answers.html" rel="alternate" type="text/html" title="Fastbook Chapter 2 Questionnaire Answers" /><published>2020-06-02T00:00:00-05:00</published><updated>2020-06-02T00:00:00-05:00</updated><id>https://butchland.github.io/butchland-machine-learning-notes/fastai/2020/06/02/fast-ai-chapter-2-prod-questionnaire-answers</id><content type="html" xml:base="https://butchland.github.io/butchland-machine-learning-notes/fastai/2020/06/02/fast-ai-chapter-2-prod-questionnaire-answers.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-02-fast-ai-chapter-2-prod-questionnaire-answers.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Questionnaire&quot;&gt;Questionnaire&lt;a class=&quot;anchor-link&quot; href=&quot;#Questionnaire&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;See &lt;a href=&quot;https://github.com/fastai/fastbook/blob/master/clean/02_production.ipynb&quot;&gt;Lesson 2&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;when data used to train the model is very different from data used in production for inferencing.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Where do text models currently have a major deficiency?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;in generating correct responses to queries.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What are possible negative societal implications of text generation models?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;automating disinformation campaigns using DL text models to generate simulated human responses.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;allow humans to oversee predictions made by ML models&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What kind of tabular data is deep learning particularly good at?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;data with high cardinality categorical columns&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What's a key downside of directly using a deep learning model for recommendation systems?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;models that predict what items users would already buy or watch even if no recommendation was made instead of recommending items that a user might buy/watch but if not for the recommendation.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What are the steps of the Drivetrain Approach?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Determine objectives&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Determine levers (inputs that can be controlled)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Determine data that can be collected to control the levers&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Build the models&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How do the steps of the Drivetrain Approach map to a recommendation system?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Objective:&lt;/strong&gt; create recommendations for items that users might like but otherwise would not be have if not for the recommendation and trigger new sales&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Levers:&lt;/strong&gt; ranking of the recommendation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data:&lt;/strong&gt; randomized experiments on a wide range of recommendations to a wide variety of customers&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Models:&lt;/strong&gt; &lt;ul&gt;
&lt;li&gt;2 Models for purchase probabilities conditional on seeing or not seeing a recommendation&lt;ol&gt;
&lt;li&gt;model - for purchases given a recommendation&lt;/li&gt;
&lt;li&gt;model - for purchases not given a recommendation&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;utility function for the difference in probabilities &lt;ul&gt;
&lt;li&gt;low &lt;ul&gt;
&lt;li&gt;when model recommends items which a customer is familiar with and rejected (both components low)&lt;/li&gt;
&lt;li&gt;when the model recommends items which a customer would have bought even with the recommendation (both high)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;high &lt;ul&gt;
&lt;li&gt;when the model recommends an item that a customer would buy if given a recommendation (large value) but low when the model does not recommend that item&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create an image recognition model using data you curate, and deploy it on the web.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TODO&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is &lt;code&gt;DataLoaders&lt;/code&gt;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;an object that specifies the way to feed data to a model&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What four things do we need to tell fastai to create &lt;code&gt;DataLoaders&lt;/code&gt;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;what kinds of data we are working with&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;how to get the items&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;how to label items&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;how to split the validation set from the training set&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What does the &lt;code&gt;splitter&lt;/code&gt; parameter to &lt;code&gt;DataBlock&lt;/code&gt; do?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;how to split the validation set from the training set&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How do we ensure a random split always gives the same validation set?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;by setting the random seed to a specific number ensures that the same pseudo random sequence is used each time to split the validation set from the training set&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What letters are often used to signify the independent and dependent variables?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;x for dependent, y for independent&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What's the difference between the crop, pad, and squish resize approaches? When might you choose one over the others?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;crop - used by default - use full height or width and crop to make it square&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pad - add zeros to smaller dimension to make it square&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;squish - scale bigger dimension to fit into square&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;squish is used when it is important to include all the image data but the model can tolerate the distortion, crop is useful when partial crops of the image can still be useful in predicting the label, pad is useful when no distortion can be allowed but at the expense of having to pad the images which might decrease the model's performance.&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is data augmentation? Why is it needed?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;alter the input slightly each time data goes through an epoch&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;improves model by reducing overfitting (not seeing the same data for each epoch due to distortions added by data augmentation)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the difference between &lt;code&gt;item_tfms&lt;/code&gt; and &lt;code&gt;batch_tfms&lt;/code&gt;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;item_tfms - transforms applied once on each sample while reading the data.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;batch_tfms - applied to entire batch - usually using GPU so its fast.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is a confusion matrix?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;a table plot that shows how many the model got right and wrong for each label category&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What does &lt;a href=&quot;/butchland-machine-learning-notes/images/copied_from_nb/export&quot;&gt;&lt;code&gt;export&lt;/code&gt;&lt;/a&gt; save?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;an inference model - a model that can be used for making predictions&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is it called when we use a model for getting predictions, instead of training?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;inferencing&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What are IPython widgets?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;components that can add interactive functionality to a jupyter notebook&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When might you want to use CPU for deployment? When might GPU be better?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPU is easier to deploy, when no training is needed&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPU is faster when making lots of parallel inferences to run through the model&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;slower response due to roundtrip time, more centralized resources required&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What are three examples of problems that could occur when rolling out a bear warning system in practice?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;data used in training is not the same data used in production&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;video not images&lt;/li&gt;
&lt;li&gt;night time &lt;/li&gt;
&lt;li&gt;video camera feed vs internet pictures &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;slow response time&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is &quot;out-of-domain data&quot;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;data used in production is not part of training data&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is &quot;domain shift&quot;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;over time, data encountered in production is not same as used in training&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What are the three steps in the deployment process?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;manual oversight&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;limited scope deployment&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gradual expansion&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Further-Research&quot;&gt;Further Research&lt;a class=&quot;anchor-link&quot; href=&quot;#Further-Research&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;ol&gt;
&lt;li&gt;Consider how the Drivetrain Approach maps to a project or problem you're interested in.&lt;/li&gt;
&lt;li&gt;When might it be best to avoid certain types of data augmentation?&lt;/li&gt;
&lt;li&gt;For a project you're interested in applying deep learning to, consider the thought experiment &quot;What would happen if it went really, really well?&quot;&lt;/li&gt;
&lt;li&gt;Start a blog, and write your first blog post. For instance, write about what you think deep learning might be useful for in a domain you're interested in.&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Fastbook Chapter 1 Questionnaire Answers</title><link href="https://butchland.github.io/butchland-machine-learning-notes/fastai/2020/06/01/fast-ai-chapter-1-intro-questionnaire-answers.html" rel="alternate" type="text/html" title="Fastbook Chapter 1 Questionnaire Answers" /><published>2020-06-01T00:00:00-05:00</published><updated>2020-06-01T00:00:00-05:00</updated><id>https://butchland.github.io/butchland-machine-learning-notes/fastai/2020/06/01/fast-ai-chapter-1-intro-questionnaire-answers</id><content type="html" xml:base="https://butchland.github.io/butchland-machine-learning-notes/fastai/2020/06/01/fast-ai-chapter-1-intro-questionnaire-answers.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-01-fast-ai-chapter-1-intro-questionnaire-answers.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Questionnaire&quot;&gt;Questionnaire&lt;a class=&quot;anchor-link&quot; href=&quot;#Questionnaire&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;See &lt;a href=&quot;https://github.com/fastai/fastbook/blob/master/clean/01_intro.ipynb&quot;&gt;Lesson 1&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Do you need these for deep learning?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Lots of math T / F&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;False - Only linear algebra + matrix math + some statistics. but it helps to have some math background to understand the underlying principles. SGD itself just relies on addition/multiplication.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Lots of data T / F&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;False - With transfer learning, you can reduce data needed; some can do with just a little data, but it depends - some problems may require more data than others. Creativity around the problem of sourcing data is key to working with limited data.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Lots of expensive computers T / F&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;False - Again, with transfer learning, you can reduce computing requirements; aside from building your own inexpensive DL rig with NVIDIA GPUs similar to gaming rigs, you can also use cloud-based solutions (both free and paid).&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A PhD T / F&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;False - practitioners can come from different backgrounds. Lots of major DL contributors are not necessarily PhDs; for example - Joseph Redmon, aka pjreddie, author of YOLO detector, a well regarded object detection library was a CS Major with no PhD.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Name five areas where deep learning is now the best in the world.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Computer Vision - image classification, image segmentation, satellite and drone imagery interpretation, facial recognition, image captioning, self driving&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Medical Imaging and Diagnosis - radiology - cancer detection, diabetic retinopathy, anomalies in radiology images, CT scans, x-ray, MRI&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Text Processing - language translation, speech to text, answering questions, summarizing docs&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recommendation Systems - Netflix, Youtube, Amazon&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Games - Alphago, Alphastar&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What was the name of the first device that was based on the principle of the artificial neuron?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mark 1 Perceptron&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Based on the book of the same name, what are the requirements for &quot;Parallel Distributed Processing&quot;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;A set of processing units (nodes/neurons - param weight)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A state of activation (activation - computation of weight + input)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;An output function for each unit (linear function + activation function e.g. ReLU)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A pattern of connectivity among units (layers of nodes using outputs from prev layer as input to next layer)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A propagation rule for propagating patterns of activities through the network of connectivities (forward propagation from layer to layer) &lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;An activation rule for combining the inputs impinging on a unit with the current state of activation to produce an output for that unit (combining activations from connected nodes)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;An learning rule where the patterns of connectivity are modified by experience (back propagation - feedback error to update param - weights)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;An environment for the machine to operate on (cycle of input+weights-&amp;gt; propagate-&amp;gt; output - performance - update weights)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What were the two theoretical misunderstandings that held back the field of neural networks?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;that neural networks could not compute even a simple XOR function (1 layer networks can't, but it can be overcome by adding more layers) &lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;that only 1 extra layer is needed to theoretically compute any function (Two layer neural networks - while theoretically could approximate any function, multiple layers were better)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is a GPU?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Graphical Processing Unit - a processor for displaying graphics, repurposed for parallelized operations needed for machine learning&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Open a notebook and execute a cell containing: &lt;code&gt;1+1&lt;/code&gt;. What happens?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;print 2 in the output&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Follow through each cell of the stripped version of the notebook for this chapter. Before executing each cell, guess what will happen.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;done&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Complete the Jupyter Notebook online appendix.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;done&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Why is it hard to use a traditional computer program to recognize images in a photo?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;it is very hard to generalize a sequence of steps to instruct a computer to recognize an image&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What did Samuel mean by &quot;Weight Assignment&quot;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;to choose the values to update the weights,setting the values of the weights of the model that will produce the correct results given the inputs&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What term do we normally use in deep learning for what Samuel called &quot;Weights&quot;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;parameters&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Draw a picture that summarizes Arthur Samuel's view of a machine learning model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;inputs + weights-&amp;gt;model-&amp;gt;outputs + labels -&amp;gt; performance -(update)-&amp;gt; weights&lt;/strong&gt;&lt;sup id=&quot;fnref-1&quot; class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn-1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Why is it hard to understand why a deep learning model makes a particular prediction?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;because of the huge number of parameters that make up a model, its very hard to attribute any one particular factor that lead a model to make a prediction and cannot always be visualized or explained, unlike an algorithm or a decision tree.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the name of the theorem that a neural network can solve any mathematical problem to any level of accuracy?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Universal Approximation theorem&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What do you need in order to train a model?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;labelled input data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;predictions which are output by model&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;loss function - compares prediction (aka predicted labels) vs actual label&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;a way to update the model based on the loss function (aka backprop, aka SGD)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How could a feedback loop impact the rollout of a predictive policing model?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;when it start optimizing towards the proxy measurement instead of the real goal, i.e. it starts optimizing arrests in lieu of reducing crime&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bias in data could lead to biased models which make biased predictions&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;biased predictions when applied to policing environment results in generating more biased data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;the updated biased data then is used to update the already biased model.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;the model seems to become &quot;more accurate&quot; but it has nothing to do with effectivity with the goal of reducing crime.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Do we always have to use 224x224 pixel images with the cat recognition model?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;no, its because we use models that have been trained traditionally on 224x224 images&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the difference between classification and regression?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;classification - where the predicted output is a limited set of categories vs regression where the predicted output is a continuous set of values&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is a validation set? What is a test set? Why do we need them?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;validation set is a set of labelled data set aside from the data used to train a model in order to predict the performance of the model when deployed to production. As the model is tweaked in order to improve its performance vis-a-vis the validation set, the validation set becomes less and less a good predictor of its eventual production performance. As a guard against this, another set of data, the test set, is also set aside, but is never used during the tweaking process. Its function is only to provide a final predictor (after tweaking) of the model's production performance.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What will fastai do if you don't provide a validation set?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;fastai will create a random split of the data provided and set aside 20 percent as the validation set&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Can we always use a random sample for a validation set? Why or why not?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;not always. if the data between the validation and training sets are correlated in some way that is not the case with the input used during production, then, the validation set is not representative of the actual production data and may provide misleading metrics as to its eventual performance.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is overfitting? Provide an example.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;overfitting is when the model has optimized itself (decreasing loss against the training data) to a level to match the training data at the expense of generality, as indicated by its worsening performance against the validation set. When a model &quot;learns&quot; the training data to a degree such that it becomes optimized only for that data that is used during its training and will do worse on data that it has not &quot;seen&quot; (e.g. validation or test sets). For example, a face recognition model that can recognize faces only on the faces used for its training, but cannot recognize faces not used during its training.&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is a metric? How does it differ to &quot;loss&quot;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;a metric is a problem specific measurement of the model's performance -- it is the performance that matters from the perspective of a model's task goal. A loss is a measurement of performance used to adjust the parameters during its training.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How can pretrained models help?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;pretrained models reduce the amount of computing resources and amount of data needed to build useful models by providing a set of weights that are better than random. By using the pre-existing parameters of the lower layers (which reflect commonalities in the different ML tasks which allow the pretrained models to be re-used), only the parameters head and upper layers need to be adjusted in order to achieve useful performance for the particular task, while the lower layer parameters need no or very fine adjustments.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the &quot;head&quot; of a model?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;the head of the model are the last few layers of the models that are specific to the task goal of the model&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What kinds of features do the early layers of a CNN find? How about the later layers?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;the early layers find the simple generic features of all images, while the later layers combine these generic features into more complex specific features for a particular task.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Are image models only useful for photos?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;any set of data that can have some meaningful spatial relationships can be converted into images that can reuse image models - examples are audio, mouse movements, etc.&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is an &quot;architecture&quot;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;an architecture is the pattern of interconnections between layers of neurons in a neural network&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is segmentation?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;segmentation is an image task of assigning a category for each pixel in an image&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is &lt;code&gt;y_range&lt;/code&gt; used for? When do we need it?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;the &lt;code&gt;y_range&lt;/code&gt; is used to specify the range of possible continuous values for the output. It is used during regression tasks&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What are &quot;hyperparameters&quot;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;the hyperparameters are the values that are adjusted during model training in order to build a useful model as quickly as possible&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What's the best way to avoid failures when using AI in an organization?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;create a validation or test set in order to evaluate the performance of any proposed AI solution in order to have a good prediction of the actual deployed model's performance.By setting aside data for an independent evaluation of the model developed for a particular task separate from the data provided for building the model, they can really develop a good sense   of the future performance of the model in the &quot;real world&quot;, separate from any evaluation by the provider of the model.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Further-research&quot;&gt;Further research&lt;a class=&quot;anchor-link&quot; href=&quot;#Further-research&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Each chapter also has a &quot;further research&quot; with questions that aren't fully answered in the text, or include more advanced assignments. Answers to these questions aren't on the book website--you'll need to do your own research!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;ol&gt;
&lt;li&gt;Why is a GPU useful for deep learning? How is a CPU different, and why is it less effective for deep learning?&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;A GPU can massively parallelize mathematical operations such as matrix multiplication needed to perform gradient descent, enabling deep networks to run adequately whereas a CPU would bottleneck on these matrix operations, slowing it down.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Try to think of three areas where feedback loops might impact use of machine learning. See if you can find documented examples of that happening in practice.&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Youtube recommendations that optimize user engagement do become addictive and can create filter bubbles that while engaging, can radicalize the user's world view because the recommendations tend to reinforce biases which are also the most likely to keep the user engaged. Same thing with facebook feed recommendations. A third example would be the predictive policing model COMPAS which has now been &lt;a href=&quot;https://www.theatlantic.com/technology/archive/2018/01/equivant-compas-algorithm/550646/&quot;&gt;criticized to be no better than random people at predicting crime&lt;/a&gt;.&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;Footnotes&quot;&gt;Footnotes&lt;a class=&quot;anchor-link&quot; href=&quot;#Footnotes&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;div class=&quot;footnotes&quot;&gt;&lt;p id=&quot;fn-1&quot;&gt;1. Samuel&amp;#39;s view of a machine learning mode &lt;a href=&quot;#fnref-1&quot; class=&quot;footnote footnotes&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_svg output_subarea output_execute_result&quot;&gt;
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;
&amp;lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot;
 &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&amp;gt;
&lt;!-- Generated by graphviz version 2.43.0 (0)
 --&gt;
&lt;!-- Title: G Pages: 1 --&gt;
&lt;svg width=&quot;477pt&quot; height=&quot;144pt&quot; viewBox=&quot;0.00 0.00 476.85 144.00&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;&gt;
&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 140)&quot;&gt;
&lt;title&gt;G&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-140 472.85,-140 472.85,4 -4,4&quot; /&gt;
&lt;!-- weights --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;weights&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;37.62&quot; cy=&quot;-118&quot; rx=&quot;37.74&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;37.62&quot; y=&quot;-113.8&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;weights&lt;/text&gt;
&lt;/g&gt;
&lt;!-- model --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;model&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;144.45&quot; cy=&quot;-72&quot; rx=&quot;32.42&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;144.45&quot; y=&quot;-67.8&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;model&lt;/text&gt;
&lt;/g&gt;
&lt;!-- weights&amp;#45;&amp;gt;model --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;weights&amp;#45;&amp;gt;model&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M65.89,-106.03C79.1,-100.24 95.1,-93.22 109.13,-87.06&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;110.72,-90.18 118.47,-82.96 107.9,-83.77 110.72,-90.18&quot; /&gt;
&lt;/g&gt;
&lt;!-- outputs --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;outputs&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;286.12&quot; cy=&quot;-72&quot; rx=&quot;36.3&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;286.12&quot; y=&quot;-67.8&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;outputs&lt;/text&gt;
&lt;/g&gt;
&lt;!-- model&amp;#45;&amp;gt;outputs --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;model&amp;#45;&amp;gt;outputs&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M176.79,-72C195.37,-72 219.23,-72 239.83,-72&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;239.95,-75.5 249.95,-72 239.95,-68.5 239.95,-75.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- performance --&gt;
&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;
&lt;title&gt;performance&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;414.06&quot; cy=&quot;-72&quot; rx=&quot;54.57&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;414.06&quot; y=&quot;-67.8&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;performance&lt;/text&gt;
&lt;/g&gt;
&lt;!-- outputs&amp;#45;&amp;gt;performance --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;outputs&amp;#45;&amp;gt;performance&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M322.54,-72C330.78,-72 339.82,-72 348.88,-72&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;349.09,-75.5 359.09,-72 349.09,-68.5 349.09,-75.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- performance&amp;#45;&amp;gt;weights --&gt;
&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;performance&amp;#45;&amp;gt;weights&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M375.97,-85.06C359.69,-90.26 340.24,-95.77 322.27,-99 239.96,-113.81 142.33,-117.34 85.73,-118.03&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;85.62,-114.53 75.65,-118.13 85.69,-121.53 85.62,-114.53&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;213.32&quot; y=&quot;-115.8&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;update&lt;/text&gt;
&lt;/g&gt;
&lt;!-- inputs --&gt;
&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;
&lt;title&gt;inputs&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;37.62&quot; cy=&quot;-64&quot; rx=&quot;31.96&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;37.62&quot; y=&quot;-59.8&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;inputs&lt;/text&gt;
&lt;/g&gt;
&lt;!-- inputs&amp;#45;&amp;gt;model --&gt;
&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;inputs&amp;#45;&amp;gt;model&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M69.22,-66.34C79.48,-67.12 91.09,-68 102.04,-68.84&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;102.02,-72.35 112.26,-69.62 102.56,-65.37 102.02,-72.35&quot; /&gt;
&lt;/g&gt;
&lt;!-- labels --&gt;
&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;
&lt;title&gt;labels&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;286.12&quot; cy=&quot;-18&quot; rx=&quot;30.97&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;286.12&quot; y=&quot;-13.8&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;labels&lt;/text&gt;
&lt;/g&gt;
&lt;!-- labels&amp;#45;&amp;gt;performance --&gt;
&lt;g id=&quot;edge6&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;labels&amp;#45;&amp;gt;performance&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M311.41,-28.41C328.11,-35.58 350.75,-45.28 370.43,-53.72&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;369.24,-57.02 379.81,-57.74 372,-50.58 369.24,-57.02&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Accountabilities</title><link href="https://butchland.github.io/butchland-machine-learning-notes/life%20hacks/2020/05/30/accountabilities.html" rel="alternate" type="text/html" title="Accountabilities" /><published>2020-05-30T00:00:00-05:00</published><updated>2020-05-30T00:00:00-05:00</updated><id>https://butchland.github.io/butchland-machine-learning-notes/life%20hacks/2020/05/30/accountabilities</id><content type="html" xml:base="https://butchland.github.io/butchland-machine-learning-notes/life%20hacks/2020/05/30/accountabilities.html">&lt;p&gt;&lt;img src=&quot;https://imgs.xkcd.com/comics/compiling.png&quot; alt=&quot;slacking off&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;accountabilities&quot;&gt;Accountabilities&lt;/h1&gt;

&lt;p&gt;One of the problems with online learning in general is that it can be a pretty lonely pursuit. After a while, if there is no one to push you, motivation can flag and your progress slows down.&lt;/p&gt;

&lt;p&gt;In a bid to prevent this, I have been active in a study group so that I have continuing activities even as we await the second part of the 2020 edition of the fastai course.&lt;/p&gt;

&lt;p&gt;Some of the activities we have is a biweekly meeting focused on presentation of projects, blog posts, etc. as well as a weekly meeting focused on reviewing the lectures and the book chapters. A third activity is a weekly meeting with a smaller group (in my case, just me, Ope and Maryam) to become accountability buddies.&lt;/p&gt;

&lt;p&gt;As part of making my accountabilities stick, I am publishing it publicly (just not searchable) so I can share my plan with my friends or study group mates and make myself accountable to them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update 6/26/2020:&lt;/strong&gt; I haven’t been able to meet my deadlines lately and so I’m adding this to reflect my updated priorities and strategies – in order to reduce my cognitive burden in maintaining schedules using this post to keep track of my targets, I’ve decided to just limit my deadline to the next thing I need to finish, and will just keep updating my deadlines for the next tasks on completion of the pending tasks. I’ll try to keep my &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1_tddHm4evJIwsfwEvh-T9RMqPVe115WlXOfr-iGj3cU/edit#gid=990074392&quot;&gt;accountability worksheet&lt;/a&gt; updated however, as its much easier to update that.&lt;/p&gt;
&lt;h2 id=&quot;my-goals&quot;&gt;My Goals&lt;/h2&gt;

&lt;p&gt;My goal is to acquire both the theoretical foundations of Machine and Deep Learning as well the practical skills to apply deep learning to particular fields such as computer vision, natural language processing and tabular data, as these are probably the most accessible applications for me right now.&lt;/p&gt;

&lt;p&gt;In addition, I also want to learn to develop and deploy ML applications on cloud platforms such as GCP, AWS and Azure.&lt;/p&gt;

&lt;h2 id=&quot;my-accountabilities&quot;&gt;My Accountabilities&lt;/h2&gt;

&lt;p&gt;My focus right now (as of June, 2020) is to deepen my understanding of deep learning. 
I plan to focus on the fastai materials for now. My goal is to build a set of lecture notes combining the video lectures and the book chapters.&lt;/p&gt;

&lt;p&gt;In addition to gaining a theoretical understanding of the topics, I also plan on developing my skills in building and training models. My goal is to build around five mini-projects with either pre-existing datasets or datasets that I build.&lt;/p&gt;

&lt;p&gt;I also plan on joining a kaggle competition in about a couple of weeks time (once I have started on the lecture notes and mini-projects).&lt;/p&gt;

&lt;h2 id=&quot;smart-goals-&quot;&gt;SMART Goals &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Lecture Notes&lt;/strong&gt; - review video, read book, answer chapter questionnaire, review other peoples answers, run notebooks, rebuild notebooks from scratch, explore notebook variants, and finally write and publish lecture notes (the deadline of each lecture note is before the start of study group reading meeting for the next lecture). See &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1TOrSfRrLD9i1He8gac9CQ2vXGzF-bnZMimyvhNc6bsg/edit#gid=0&quot;&gt;tracker&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Lecture 1 (app_jupyter and ch1 intro) and Lecture 2 (ch2 production) - June 2, 2020 &lt;em&gt;(edit 6/26: finished ch1 intro and reset sched for ch2 to June 29,2020)&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Lecture 3 (ch 2 production and ch4 mnist basics ) and Lecture 4 (ch4 mnist basics and ch5 pet breeds) - June 9, 2020 &lt;em&gt;(edit 6/10: reset sched to TBD - after completion of ch2)&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Lecture 5 (ch 3 ethics) and Lecture 6 (ch5 pet breeds and ch6 multicat) - June 16, 2020 &lt;em&gt;(edit 6/26: reset sched to TBD after completion of ch5)&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Lecture 7 (ch 8 collab and ch 9 tabular) - June 23, 2020 (edit 6/226: reset sched TBD after completion of ch6)&lt;/li&gt;
      &lt;li&gt;Lecture 8 (ch 10 nlp and ch 12 nlp dive) - June 30, 2020 (edit 6/26: reset sched TBD after completion of ch 9)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Mini projects&lt;/strong&gt; &lt;em&gt;(todo)&lt;/em&gt; - should cover computer vision, nlp, tabular, collab filter&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Baybayin (filipino script) handwriting recognition system
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://github.com/butchland/fastai_nb_explorations/blob/master/baybayin_handwritten_character_dataset_initial_eda.ipynb&quot;&gt;initial data download and exploration (eda)&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://github.com/butchland/fastai_nb_explorations/blob/master/baybayin_handwritten_character_dataset_initial_model_build.ipynb&quot;&gt;initial model build&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;em&gt;TODO&lt;/em&gt;: build canvas image writer web app with baybayin recognition (with pytorch js) ?
            &lt;ul&gt;
              &lt;li&gt;github: &lt;a href=&quot;https://github.com/bensonruan/Hand-Written-Digit-Recognition&quot;&gt;Hand-Written-Digit-Recognition&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;github: &lt;a href=&quot;https://github.com/bhuwanaryal19/nepali_digit_recognizer&quot;&gt;nepali-digit-recognizer&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Selfie/Faces - gender recognition system ?&lt;/li&gt;
      &lt;li&gt;Twitter sentiment140 analysis (NLP) ?&lt;/li&gt;
      &lt;li&gt;Image Recognition (face) celebrity ?&lt;/li&gt;
      &lt;li&gt;fingers recognition
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://github.com/butchland/fastai_nb_explorations/blob/master/CollectRealFingersData.ipynb&quot;&gt;collect fingers data&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://github.com/butchland/fastai_nb_explorations/blob/master/ExploreKaggle.ipynb&quot;&gt;explore kaggle&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://github.com/butchland/fastai_nb_explorations/blob/master/ExploreKoryakinFingers.ipynb&quot;&gt;explore koryakin fingers&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://github.com/butchland/fastai_nb_explorations/blob/master/TestKoryakinFingersModel.ipynb&quot;&gt;test koryakin fingers model&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;SVHN house numbers recognition&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Long term project&lt;/strong&gt; &lt;em&gt;(todo)&lt;/em&gt; - build up ML Portfolio&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Kaggle competition ?&lt;/li&gt;
      &lt;li&gt;Detecting OOB (out of bounds) data&lt;/li&gt;
      &lt;li&gt;Filipino caption translation of fastai videos ?&lt;/li&gt;
      &lt;li&gt;Deep Learning Adventure Guide ?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Fun projects&lt;/strong&gt; &lt;em&gt;(todo)&lt;/em&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;DDG Image Downloader enhancements to use full size orig images
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://github.com/butchland/ddg_images_downloader&quot;&gt;current project (using bing images)&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://butchland.github.io/ddg_images_downloader&quot;&gt;nbdev generated page for project&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Update my pet-breed-classifier-demo to use fastai2&lt;/li&gt;
      &lt;li&gt;React Native mobile app with image recognition (template)&lt;/li&gt;
      &lt;li&gt;React/Vuejs Webapp with image recognition (template) ?&lt;/li&gt;
      &lt;li&gt;Godot game with image recognition or NLP (template) ?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/SMART_criteria&quot;&gt;SMART Goals - Specific, Measurable, Achievable, Relevant, Timebound&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">Accountabilities</summary></entry><entry><title type="html">Machine Learning Foundations</title><link href="https://butchland.github.io/butchland-machine-learning-notes/machine%20learning/2020/04/27/machine-learning-foundations.html" rel="alternate" type="text/html" title="Machine Learning Foundations" /><published>2020-04-27T00:00:00-05:00</published><updated>2020-04-27T00:00:00-05:00</updated><id>https://butchland.github.io/butchland-machine-learning-notes/machine%20learning/2020/04/27/machine-learning-foundations</id><content type="html" xml:base="https://butchland.github.io/butchland-machine-learning-notes/machine%20learning/2020/04/27/machine-learning-foundations.html">&lt;p&gt;&lt;img src=&quot;/butchland-machine-learning-notes/images/j586af7nxvu41.jpg&quot; alt=&quot;train models&quot; title=&quot;credit to https://i.redd.it/j586af7nxvu41.jpg&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;introduction-to-machine-learning-deep-learning-and-neural-networks&quot;&gt;Introduction to Machine Learning, Deep Learning and Neural Networks&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;These notes are my attempt to implement Feynman’s method of
learning, whereby, from memory (with as few glances to Wikipedia as I can), 
I attempt to reconstruct my understanding of deep learning so far.&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Since I am trying to recreate this from memory, I may not have references to some of the stuff I’m saying – but every now and then, as I update this (and possibly other) document, I might include them just to make it easy to confirm what I’m saying.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Last note:&lt;/strong&gt; this document will be rambling jumble of thoughts that hopefully over time will be reorganized better into a wiki. There will be lots of repetition of ideas and maybe some of it will be wrong, but as I go over them, hopefully this will occur less and less.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Last last note:&lt;/strong&gt; I am writing this from the perspective of me trying to explain to a fellow developer how machine learning works. Its not very in depth yet, but over time I hope to go
deeper into the topics all the way to showing the code while explaining the theory.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;outline-and-topics&quot;&gt;Outline and Topics&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Definitions - &lt;em&gt;I still plan to organize this – this is just a plan for what topics to cover.&lt;/em&gt;)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Machine Learning&lt;/li&gt;
      &lt;li&gt;Neural Network Model&lt;/li&gt;
      &lt;li&gt;Model Training&lt;/li&gt;
      &lt;li&gt;Deep Learning&lt;/li&gt;
      &lt;li&gt;Gradient&lt;/li&gt;
      &lt;li&gt;Gradient Descent&lt;/li&gt;
      &lt;li&gt;Stochastic Gradient Descent&lt;/li&gt;
      &lt;li&gt;Loss and Loss Function&lt;/li&gt;
      &lt;li&gt;Activation Function&lt;/li&gt;
      &lt;li&gt;Linear Function&lt;/li&gt;
      &lt;li&gt;Optimization&lt;/li&gt;
      &lt;li&gt;Learning Rate&lt;/li&gt;
      &lt;li&gt;Training, Validation and Test Datasets&lt;/li&gt;
      &lt;li&gt;Parameter Initialization and Transfer Learning&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;foundations&quot;&gt;Foundations&lt;/h2&gt;

&lt;h3 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Machine Learning (ML)&lt;/strong&gt; is an alternative way of programming a computer whereby a computer learns to perform some task by being given some examples.&lt;/p&gt;

&lt;p&gt;This is in contrast to the &lt;em&gt;usual&lt;/em&gt; way of programming computers to do a task by specifying the steps in some detail.&lt;/p&gt;

&lt;p&gt;The mechanism by which ML accomplishes this process of learning to do tasks through examples is by using neural network models.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;Neural Network Model&lt;/strong&gt; is a program that can learn to perform tasks by being shown examples.&lt;/p&gt;

&lt;p&gt;Using a set of given examples, a model:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;tries to perform a task, and&lt;/li&gt;
  &lt;li&gt;its performance (i.e. how well it performs that task) is then measured, and&lt;/li&gt;
  &lt;li&gt;that measurement is then used to adjust the model in such a way that affects (hopefully improves) its performance.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a concrete example, if we wanted to create a cat-dog image recognition program, we could start with a model and a lot of cat and dog images.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The model first tries to predict that given the images as input, it makes guesses as to whether each example is a cat or dog.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Its performance (whether it guessed correctly or not) is then measured in some way,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;And that measurement is then used to adjust the model so that the next time it tries to make a prediction, it does a better task.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;And the task is repeated again and again, with the model (hopefully) continually improving until its good enough at distinguishing cats from dogs.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;model-training&quot;&gt;Model Training&lt;/h3&gt;

&lt;p&gt;This process of performing a task, measuring its performance, and adjusting the model is known as &lt;strong&gt;training the model&lt;/strong&gt; or model training.&lt;/p&gt;

&lt;p&gt;Once a model’s performance reaches an optimum level (e.g. a cat-dog image recognition neural network model correctly distinguishes cats from dogs 99.995% of the time), it can then be used to perform that task just like any other computer program.&lt;/p&gt;

&lt;h3 id=&quot;the-model-as-a-function&quot;&gt;The Model as a Function&lt;/h3&gt;

&lt;p&gt;A good way to approach machine learning is to look at a Neural Network Model as a function that computes an output given a set of inputs.&lt;/p&gt;

&lt;h3 id=&quot;neural-network-models-and-neurons&quot;&gt;Neural Network Models and Neurons&lt;/h3&gt;

&lt;p&gt;A model is basically a function that is composed of a set of processing units interconnected in a particular architecture. Each processing unit is called a &lt;strong&gt;neuron&lt;/strong&gt; or a node, and each neuron takes in a set of inputs (which are numerical input values), and outputs a result (the numerical output value). So we can also consider these neurons as functions as well.&lt;/p&gt;

&lt;h3 id=&quot;parameters-weights-and-biases&quot;&gt;Parameters, Weights and Biases&lt;/h3&gt;

&lt;p&gt;Associated with each neuron is a set of &lt;strong&gt;parameters&lt;/strong&gt;. This set of parameters can be further divided into &lt;strong&gt;weights&lt;/strong&gt; and &lt;strong&gt;biases&lt;/strong&gt;. Associated with &lt;em&gt;each input&lt;/em&gt; to a neuron is a &lt;strong&gt;weight&lt;/strong&gt;, which is a type of a parameter. Associated with &lt;em&gt;each neuron&lt;/em&gt; itself is a &lt;strong&gt;bias&lt;/strong&gt;, which is the other type of parameter. The output of each neuron can then be the inputs to another set of neurons, which combine inputs and outputs to inputs and outputs of other sets of neurons and to finally to output a result (which may be a category, a number or a set of numbers) which is the output of the model itself.&lt;/p&gt;

&lt;h3 id=&quot;neural-network-layers&quot;&gt;Neural Network Layers&lt;/h3&gt;

&lt;p&gt;These neurons are usually organized into &lt;strong&gt;layers&lt;/strong&gt;, with the outputs of one layer of neurons feeding into the inputs of the next layer of neurons.&lt;/p&gt;

&lt;h3 id=&quot;activation-functions&quot;&gt;Activation Functions&lt;/h3&gt;

&lt;p&gt;Between the connections of these neurons are the &lt;strong&gt;activation functions&lt;/strong&gt;, which transform the output of the previous layer in some way before feeding it as the input of the next layer.&lt;/p&gt;

&lt;h3 id=&quot;architecture&quot;&gt;Architecture&lt;/h3&gt;

&lt;p&gt;The way these layers interconnect their neurons is known as the &lt;strong&gt;architecture&lt;/strong&gt; of the model.&lt;/p&gt;

&lt;h3 id=&quot;deep-learning&quot;&gt;Deep Learning&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Deep learning&lt;/strong&gt; is the term associated with the usage of neural networks that have many layers and is the primary reason for the revival of machine learning as a useful tool in many fields today.&lt;/p&gt;

&lt;h3 id=&quot;an-image-recognition-example&quot;&gt;An Image Recognition Example&lt;/h3&gt;

&lt;p&gt;As an example, we can say that a trained cat-dog image recognition neural network model is a function that can take as an input an image and outputs a result, telling us whether the image is a picture of a cat or a dog.&lt;/p&gt;

&lt;p&gt;The way we can make the model do this is by adjusting the parameters of the model in such a way that it can do the task of image recognition – recognizing cats from dogs.&lt;/p&gt;

&lt;p&gt;So now the problem becomes how do we come up with a set of parameters for the model so that it does the task well. This is done by training the model with example images of cats and dogs.&lt;/p&gt;

&lt;h3 id=&quot;training-the-model&quot;&gt;Training the Model&lt;/h3&gt;

&lt;p&gt;In order to train a model, it is given a set of inputs, known as the training dataset (which for the image
recognition task of distinguishing cats from dogs, the inputs are images of cats and dogs).&lt;/p&gt;

&lt;p&gt;Aside from the input data, there needs to be some target output (also called a label) associated with each input, which in the case of cat-dog image recognition task, is a label telling us that each input image is either a cat or a dog. So we can’t just have pictures of cats and dogs, we need to have &lt;em&gt;labelled&lt;/em&gt; examples of 
cat and dog images.&lt;/p&gt;

&lt;p&gt;The task of an image recognition model is then, given an input image, is to make a prediction, i.e. output a result. This result is then compared to the target output (i.e. the correct label) for each input image.&lt;/p&gt;

&lt;p&gt;How much the model output is right or wrong for each input (for classification tasks), or how far the model is wrong or right for a continuous value (for regression tasks) is known as the &lt;strong&gt;loss&lt;/strong&gt;. The loss is usually (but not necessarily always) computed in such a way that the more accurate or better the model is in making a prediction, the smaller the loss.&lt;/p&gt;

&lt;p&gt;This function that measures the difference between the target output versus the output predicted by the model is known as the &lt;strong&gt;loss function&lt;/strong&gt;. So we can say that the loss function which the one that produces a measure of a model’s performance.&lt;/p&gt;

&lt;p&gt;Once a loss is computed (this is a numerical value that indicates how well a model is doing its task, usually the smaller the better), the next step is to improve or optimize the model’s performance by adjusting the weights.&lt;/p&gt;

&lt;p&gt;How it does that computation of the adjustment is done by an algorithm known as Gradient Descent, which is one of the secret ingredients (if ever there was one) behind the power of neural networks.&lt;/p&gt;

&lt;h4 id=&quot;supervised-learning-and-other-types-of-learning&quot;&gt;Supervised Learning and Other Types of Learning&lt;/h4&gt;

&lt;p&gt;Because this machine learning process uses a set of labelled data (associated with each input data is the target result or label, whether this is a category or a continuous number) which used to check the models predictions if they correct or not (in other words, the  labels are used to supervise whether the model is behaving correctly), it is called &lt;strong&gt;supervised learning&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;There are other methods that don’t use labels as such – as in &lt;strong&gt;unsupervised learning&lt;/strong&gt; where the model uses unlabeled data to extract patterns that maybe useful in classifying the data. Another approach is called &lt;strong&gt;semi-supervised or self-supervised learning&lt;/strong&gt; where the labels maybe embedded in the input data itself.&lt;/p&gt;

&lt;p&gt;An example of this is in &lt;strong&gt;Natural Language Processing (NLP)&lt;/strong&gt; where models might use text from Wikipedia and other sources as the input data and the model is trained such that it can extract the patterns from the underlying language, for example, in language generation, such that given a sequence of words, the model is able to predict the next word or next sets of words that will appear in a sentence or paragraph. The “labels” as such are embedded or latent in the data of the text itself, so while there is no explicit label, the goal is to create a model, given a start of a sentence, might be capable of being able predict what the missing word or words might be. So the goal or loss function might be to improve the accuracy of the prediction and therefore a model can be trained this way, despite the input data not having explicit labels associated with it.&lt;/p&gt;

&lt;p&gt;Another area of machine learning is Reinforcement Learning, where a model takes on a task such as playing a video game or Go or chess, where the loss function is to minimize its losses (and/or maximize its wins). And by playing against a copy of itself, the model learns what strategies leads to success or failures and keeps improving and improving until, for example, it could beat their human counterparts.&lt;/p&gt;

&lt;p&gt;This article will be focused primarily on supervised learning as this is the basic building block for all the other methods.&lt;/p&gt;

&lt;h3 id=&quot;gradient-descent&quot;&gt;Gradient Descent&lt;/h3&gt;

&lt;p&gt;As stated previously, &lt;strong&gt;Gradient Descent&lt;/strong&gt; is the process that models use in order to adjust their parameters towards some goal.&lt;/p&gt;

&lt;p&gt;We can think of the neural network as a whole (even though it is actually composed of layers and layers of neurons) as actually just being a function. It is a function that outputs a y given a set of inputs x. Moreover, it outputs the y based on input x and a set of parameters w (weights) and b (biases).&lt;/p&gt;

&lt;p&gt;So given a fixed set of inputs x (e.g. a set of N samples of images), modifying the parameters w and b slightly will cause the model to output a slightly different result and hopefully a change in the loss. The change in the loss (delta of the loss) resulting from a slight change of the parameter (delta of the parameter) is known as the &lt;strong&gt;gradient&lt;/strong&gt;. For linear functions, this gradient is also known as the slope (or rise/run). In other words, a gradient for a parameter tells us how changing that parameter (which may number in the thousands for a typical model) affects the loss.&lt;/p&gt;

&lt;p&gt;Once we know the gradients of the parameters, we can then adjust the parameters in such a way as to reduce
the loss (in other words, improve the performance).&lt;/p&gt;

&lt;p&gt;Gradient Descent works by computing the gradients of parameters p with respect to a given set of inputs x and its computed outputs yhat , the target outputs y and the resulting loss (&lt;em&gt;a math like jargon definition&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;Each parameter is then updated (reduced or increased) by an amount equal to the gradient of that parameter multiplied by a factor known as the Learning Rate.&lt;/p&gt;

&lt;p&gt;Then the model is tested again, by computing the output yhat given the input x and the adjusted parameters p.
The loss is then again computed based on the adjusted parameters. If done correctly, the loss should now be smaller and the model improves its performance.  Looping through this process (and keeping track of its performance) again and again, will theoretically, eventually result in a model that can be good enough for the targeted task.&lt;/p&gt;

&lt;p&gt;The process by which a model computes a loss using a loss function, computes the gradients of the parameters with respect to that loss, and the update of the parameters in order to improve its performance is known as &lt;strong&gt;optimization&lt;/strong&gt; and is done by another component (not part of the model) known as an &lt;strong&gt;optimizer&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The process of computation of the gradients is known as &lt;strong&gt;backpropagation&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The process of the neurons’ computation of the inputs into their outputs and subsequent input to the next layer of neurons all the way through the layers to output a predicted result for the model is known as &lt;strong&gt;forward propagation&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;One important function that needs to happen during forward propagation phase is that the framework that is used to implement the neural network models needs to keep track of the calculations being done by the neurons on the parameters, the activation functions all across the layers of the model up to the calculation of the loss.&lt;/p&gt;

&lt;p&gt;This sequence of calculations, or more accurately, graph of calculations is known as the model’s &lt;strong&gt;computational graph&lt;/strong&gt;. This computational graph is then used by the framework to compute the parameters’ gradients in the backpropagation phase of the training.&lt;/p&gt;

&lt;p&gt;When the trained model is used to compute a prediction based on a new set of inputs (such as in model deployed in production), this forward propagation is also called inference. Normally, during inference, the model is still forward propagation, but the framework no longer needs to create a computational graph because it doesn’t need to compute the gradients of the parameters – the gradients are only needed when we plan to update the parameters, but computing the output does not need the gradients, and are usually turned off.&lt;/p&gt;

&lt;h3 id=&quot;stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/h3&gt;

&lt;p&gt;In the process we described above, we assumed our computation of loss (and the subsequent computation of the gradients) based on all the samples of the training data once every epoch (where an epoch is one pass through all training data).&lt;/p&gt;

&lt;p&gt;In practice, this is very hard to do, due to limitations of GPU hardware (usually memory) in which the operations to compute the predictions, computation of the loss, computation of the gradients, and update of the parameters are all done by a GPU so these pieces of data need to be stored in GPU memory which might be less than the memory available for the CPU.&lt;/p&gt;

&lt;p&gt;The reason we have to use a GPU is because the number of parameters can be very large and while the operations might be simple (multiplication, addition, differentiation (aka computation of the gradients) - even differentiation is just multiplication and adddition), there needs to be lots of them, and GPUS are ideal for this soft of computation because they can be parallelized.&lt;/p&gt;

&lt;p&gt;One alternative to computing the loss for the all the samples at once, is to compute the loss (and the subsequent gradients) for each sample of input data (e.g. one image at a time) and update the weights as we pass through all the samples. In this extreme case, an epoch (where an epoch is one pass through all your training data) consists of N passes of the training loop given N samples of training data. This is known as online or sequential gradient descent and is considered a variant of stochastic gradient descent.&lt;/p&gt;

&lt;p&gt;A more common alternative is the middle ground where we take a batch of n input samples at a time (call this batch size bs) and compute the loss, compute the gradients and adjust the parameters for the entire batch. This means that as the model goes through each batch, the model is computing the loss from each batch and applying the update to the model’s parameters to be used for the predictions of the next batch to see if its update does result in a lower loss (i.e. improve the model’s performance).&lt;/p&gt;

&lt;p&gt;So for a given batch size &lt;em&gt;bs&lt;/em&gt;, there will be &lt;em&gt;m&lt;/em&gt; batches where &lt;em&gt;m&lt;/em&gt; is equal to &lt;em&gt;N&lt;/em&gt; input samples divided by the batch size &lt;em&gt;bs&lt;/em&gt;. This means that for each epoch, there will be &lt;em&gt;m&lt;/em&gt; passes through the training loop. This is known as batch gradient descent and is also considered as a variant of stochastic gradient descent.&lt;/p&gt;

&lt;p&gt;This can maximize the utilization of the GPU as we can adjust the batch size so that the entire input data for each batch plus the parameters can fit into the GPU memory.&lt;/p&gt;

&lt;p&gt;Also, we can also consider online or sequential gradient descent as a batch gradient descent with a batch size of one.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;As an aside, Stochastic means randomly determined. The reason why the we call the online and batch gradient descent stochastic is because they replace the computation of the loss of the entire input data with a stochastic (random) approximation (based on a sample subset of the input data). Moreover, as the same input data is read passed through each epoch, the contents of each batch are usually shuffled, resulting in a set of parameters that can better approximate the parameters for the entire input data through random sampling.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;hyperparameters&quot;&gt;Hyperparameters&lt;/h3&gt;

&lt;p&gt;The learning rate, the batch size and the number of epochs are the tweaks in the way we train our model, and along with lots of others (including the architecture), are known as hyperparameters. Learning to pick what good values to set these to will, (along with how good your training data is, as well) determine how quickly or how well we can build a model to perform a target task.&lt;/p&gt;

&lt;p&gt;Unfortunately, at this point, this process of finding the right hyperparameters is as much as an art and a skill that can only be developed through experience, although there might be some rules of thumb that we can follow. Often, the only way to know is by trying things out and is often a source of challenge as much as a source of frustration for deep learning practitioners.&lt;/p&gt;

&lt;h3 id=&quot;linear-functions-and-activation-functions&quot;&gt;Linear Functions and Activation Functions&lt;/h3&gt;

&lt;p&gt;The most common function used in the neurons that compose the layers of neural networks is the &lt;em&gt;linear function wx + b&lt;/em&gt;, where x represents the inputs, w the weights and b is the bias. In order for a neuron (or a layer of neurons) to implement Gradient Descent, it is important that its function be differentiable, meaning a gradient can be computed on the parameters w and b given a loss function that computes the output of the last layer of the model.&lt;/p&gt;

&lt;p&gt;It is also important to note that for each layer in the neural network , the input x might be a set of numbers, e.g. a vector or a matrix of numbers, and that the weights can also be matrices and biases can also be vectors, so a more accurate depiction of the linear equation is w@x + b where @ represents a matrix multiplication.&lt;/p&gt;

&lt;h4 id=&quot;an-alternate-formulation-of-the-linear-function-and-an-explanation-for-usage-of-the-word-bias&quot;&gt;An alternate formulation of the Linear function (and an explanation for usage of the word bias)&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;As an alternate formulation, the linear equation w@x + b can also be expressed as w@x, but with the
slight modification of the x inputs – the addition of an input(possible a vector) = 1 and the weights w incorporating the bias at the end of the matrix. So the inputs always include an additional input that is always equal to 1 while the weights now incorporate the bias as the last column. multiplying the input of 1 with the weight b is equal to b – so this is equivalent to w@x + b. The reason why it is called bias is that a bias is a term used in electrical circuits for a component that raises the output to a constant value - even when the rest of the inputs are zero. The advantage of this formulation is that it simplifies differentiation (i.e. the computation of the gradients, since everything that needs to be differentiated is in the matrix w, including the bias, albeit at the expense of having to add an extra input value equal to 1 during the computation of the prediction)&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;activation-functions-1&quot;&gt;Activation Functions&lt;/h3&gt;

&lt;p&gt;Activation functions on the other hand are transformations between the outputs of one layer to the inputs of the next layer. Their function is to introduce a non-linearity between the linear functions of the neurons.&lt;/p&gt;

&lt;p&gt;Mathematically, tying together the output of a linear function to the input of another linear function is actually equivalent to just another linear function. So if the neural network was simply composed of layers of neurons computing linear equations linked directly (i.e. their output was fed directly) to the next layer of neurons also computing linear equations down the line, it would simply be equivalent to a single layer of neurons computing linear equations. And neural networks composed only of one layer are not going to be able to do the feats that deep learning neural networks have become famous for.&lt;/p&gt;

&lt;p&gt;An example of a non-linear function is the ReLU or rectified linear unit. In practical terms, its just a function that replicates (and outputs) the input if the input is greater than zero, otherwise, it just outputs zero. In other words, it just zeroes out the negative outputs and passes on the positive outputs.&lt;/p&gt;

&lt;p&gt;Now, this may not sound such a radical transformation, but this, along with the Gradient Descent, allows any neural network to theoretically approximate any function, given a set of inputs. This capability of neural networks to approximate any computation for a given set of inputs is known as the Universal Approximation Theorem. If anything, activation functions are the other secret ingredient behind the power of neural networks.&lt;/p&gt;

&lt;h3 id=&quot;loss-functions&quot;&gt;Loss functions&lt;/h3&gt;

&lt;p&gt;An important characteristic of a good loss function is that it should be sensitive to changes in the parameters, i.e. slight changes to the parameters should also change the computed loss. This is so that when we differentiate the loss function and compute the gradients of the parameters, the change in the loss will result in non-zero values for the gradients. This, in turn, will trigger a change in the parameters (because they are adjusted by an amount equal to the value of the gradient multiplied by a factor known as the learning rate) for the iteration of the training loop.&lt;/p&gt;

&lt;p&gt;If a loss function was not sensitive to changes in the parameters (i.e. slight changes in the parameter results in the same value of loss), then gradients computed would be zero and so the adjustment would also be zero (zero gradient times any value of learning rate is also zero) and would end up in no change in the parameters (ad infinitum). At this point, the model would no longer be improving – another way of saying that the model is no longer learning.&lt;/p&gt;

&lt;p&gt;We can visualize the all possible parameter values as occupying a multi-dimensional space and the loss function maps each point in this space to a numerical value (given a fixed set of inputs). Moving slightly from one point in this parameter space to another point results in another value for the loss.  A bad loss function is one with lots of flat areas (i.e. zero gradients) while good loss functions would have hills and valleys leading down to (hopefully) a global minimum or at least something close to it.&lt;/p&gt;

&lt;p&gt;The goal of training the model is to find a multidimensional point in this parameter space (in other words the set of parameters ws and biases for the entire model) that computes a minimum loss for the entire training data.&lt;/p&gt;

&lt;h3 id=&quot;metrics&quot;&gt;Metrics&lt;/h3&gt;

&lt;p&gt;While we’ve already talked a little bit about loss functions and how they’re used to improve the model using gradient descent, from a practical perspective, what we really care about a model’s performance is known as its metrics.&lt;/p&gt;

&lt;p&gt;So a metric is also a measurement of the performance of a model, but unlike the loss function, it doesn’t have to be differentiable, it just has to be a reasonable measure of performance from the practitioner’s perspective. Sometimes you can use the loss as the metric, but you might be able to use something more appropriate and understandable.&lt;/p&gt;

&lt;p&gt;One of the most common metrics (especially for classification) we use is error rate - given a sample of N inputs, how many mistakes (or wrongly classified) M did it make, and the error rate is M divided by N. The lower it is, the better. Zero error rate means no mistakes. As an alternative, we can also take accuracy – which is just 1 - error rate (or how many correct responses did the model make given N input samples).&lt;/p&gt;

&lt;p&gt;For regression tasks (where the model is predicting a continuous value), the MSE or Mean Squared Error or 
its square root (aka RMSE) can be used as a metric. Note that in this case, the MSE can also be used as the loss function.&lt;/p&gt;

&lt;h3 id=&quot;overfitting-and-validation-sets&quot;&gt;Overfitting and Validation Sets&lt;/h3&gt;

&lt;p&gt;The next question is to what set of samples do we apply the metrics to? If we simply use the training data, it is very easy to get zero error rates (usually). But when we actually try to use the model in production, we might get disappointed and not get the same performance (metric wise) that we got during training.&lt;/p&gt;

&lt;p&gt;The reason for this might be that our model has been optimized to such an extent that its has become so  specialized so as to match the training data that it is no longer performs as well on data that you use during production.&lt;/p&gt;

&lt;p&gt;The model might have seen your training data so many times that it has sort of “memorized” it and can give good predictions on it but it won’t necessarily perform well on data it hasn’t seen during training. This situation where the model performs (both the loss and your metrics) well on your training data but doesn’t do so well on data it didn’t see during training is known as overfitting.&lt;/p&gt;

&lt;p&gt;In order to counter this, and to also have a better estimate of the model’s performance when we deploy it during production, we can simulate this set of data we will encounter during production by setting aside some of our labelled data that we would normally use for training the model to be used to validate its performance. This set of data is what we call our validation data, as distinct from the training data.&lt;/p&gt;

&lt;p&gt;This validation data is where we apply our metrics in order to get an estimate of the performance of our model when we deploy it in production. These metrics are much less useful when we apply them to our training data because they won’t give a good estimate of the model’s performance when used in production (often, they inflate the performance and give us a false sense of confidence). This is why we mostly track our metrics against the validation data, not on the training data.&lt;/p&gt;

&lt;p&gt;Also, it is also very important to note that our training and validation data that we use for training the model as well as estimating its performance should be as representative as possible of the data that we will actually encounter when we deploy the model into production.&lt;/p&gt;

&lt;p&gt;This is important for the training data, as the model can only learn based on the input data that it encounters, and may not perform as well on data that is very different that it may encounter during production.&lt;/p&gt;

&lt;p&gt;This is also important for the validation data, because if the validation data is not representative of the data it will encounter in production, we might have a  wrong estimate the performance of the model when it is actually used in production if we base it on the metrics we measure on the validation data.&lt;/p&gt;

&lt;p&gt;The last point we need to make is that we need to split the validation data from the training data in such a way that the data we use in the validation set is representative of the data we will encounter in production. So for example, if in production, we will have images of cats and dogs that we didn’t have in our training data, then our validation data should also have images of cats and dogs that are not part of our training data.&lt;/p&gt;

&lt;p&gt;If didn’t do this, and we use the same images in both our training and validation data, then its quite possible that we would score high on our metric (because it may have “memorized” the training data) but most certainly perform worse when we actually use it in production.&lt;/p&gt;

&lt;p&gt;One way to approach this splitting of training and validation data is to make sure that our validation data is not “leaking” into our training data. If, for example, our samples that are in the validation data can somehow be correlated into samples that are also in the training data in a way that will never happen in production, then that might constitute a “leakage”. What constitutes this leakage is of course very dependent on model’s task and the data we use to train it.&lt;/p&gt;

&lt;h3 id=&quot;using-the-metrics-to-improve-the-model&quot;&gt;Using the metrics to improve the model&lt;/h3&gt;

&lt;p&gt;If we do the training-validation split correctly, then our validation metrics should be a good predictor
of the model’s performance when it is deployed in production. As such, we can use the metrics to guide us on tweaking the model until its metrics are good enough or even tell us to stop if the metrics start to worsen. 
We can also use it to compare different models and allow us to pick the one with the best performance.&lt;/p&gt;

&lt;p&gt;As we learn different techniques and learn different “hyperparameters” to tweak the model, at some point, that although the model does not use or “see” the validation data during its training, we, as the practitioners guiding the process of selecting hyperparameters towards a set of the model’s parameters that result in a good performance metric on the validation data, we might have actually started “overfitting” the model to match the validation data, at the expense of worsening its performance on data it will encounter once we deploy it in the real world. Though less of a possibility, it is still a possibility.&lt;/p&gt;

&lt;h3 id=&quot;test-datasets&quot;&gt;Test Datasets&lt;/h3&gt;

&lt;p&gt;In order to counter this “leakage” of the validation data into the model, one possible solution is to set aside a third set of data known as the test data. This is again split from the labelled data and the usual caveats apply, i.e. it must be representative of the data the model will encounter in the real world and must not be correlated with samples present in the training and validation data. This test data will not be used in the training process and when we are updating the hyperparameters and validating the performance metrics using the validation dataset. It will only be used to predict the performance of the model once all the tweaking has been done.&lt;/p&gt;

&lt;h3 id=&quot;tracking-the-performance-of-the-model-during-training&quot;&gt;Tracking the performance of the model during training&lt;/h3&gt;

&lt;p&gt;As we go through each epoch (each epoch is a complete pass through all your training data), and since we are using batch gradient descent where for each epoch we have subdivided your training data into batches, we will be executing the training loop for each batch and updating the model’s parameters each time we pass through the training loop.&lt;/p&gt;

&lt;p&gt;In order to give us an idea of the current performance of the model, at the end of the training loop for all batches, we can then compute the metrics and loss on the validation dataset, doing the inferencing (making sure we do this without updating the computational graph since only the forward propagation steps on the training data should be updating the computational graph since its the gradients on the training input data that should be used to update parameters).&lt;/p&gt;

&lt;p&gt;The computation of the validation loss and metrics are also done in batches using the GPU because they run quicker if they are parallelized, but usually the batch sizes are double the batch sizes for the training phase because they dont use the computational graph to track the calculations on the inference and loss calculations. At the end of all the validation batches, the means of the validation loss and metrics are displayed along with the training loss to give an indication of the model’s performance.&lt;/p&gt;

&lt;h3 id=&quot;parameter-initialization-and-transfer-learning&quot;&gt;Parameter Initialization and Transfer Learning&lt;/h3&gt;

&lt;p&gt;In the section on &lt;a href=&quot;#model-training&quot;&gt;training the model&lt;/a&gt;, especially for the cat-dog image recognition example, we did some hand waving on how we actually get a starting point for the model.&lt;/p&gt;

&lt;p&gt;Remember, we can usually define an architecture (which is how the many neurons there are in each layer, how many layers and how each layer connects to the other layers), but we haven’t discussed how we come up with the initial values for the parameters themselves.&lt;/p&gt;

&lt;p&gt;If we didn’t have any other starting point, the way practitioners usually set the initial parameters are by setting them to random values.&lt;/p&gt;

&lt;p&gt;Of course, there are also particularities in the way we setup these random parameters but the idea is that whatever random values they start with, during the training phase, these parameters converge to a set of values that will provide the optimum level of performance needed to perform a task.&lt;/p&gt;

&lt;p&gt;As an alternative to starting out with random values, we could also use a model trained on a similar task but not necessarily the same as the task we want the model to optimize. This idea of using an pre-existing pre-trained model and adapting it to your particular task is known as &lt;strong&gt;transfer learning&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Transfer learning, if done with the appropriate pre-existing pre-trained model, can reduce the amount of data and computation needed to reach an optimum level of performance.&lt;/p&gt;

&lt;p&gt;This is the primary reason why, by using transfer learning, we can reach state of the art performance even on limited computing requirements and limited amounts of labelled data.&lt;/p&gt;

&lt;p&gt;For computer vision tasks, these pre-trained image recognition models usually come in a set of well defined architectures that have been known to perform well in some competititon and have usually been trained on large image datasets.&lt;/p&gt;

&lt;p&gt;&lt;sub&gt;Copyright &amp;copy; 2020 by Butch Landingin. All rights reserved. version 0.1.11&lt;/sub&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://www.calnewport.com/blog/2015/11/25/the-feynman-notebook-method/&quot;&gt;Feynman Method&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">Introduction to Machine Learning, Deep Learning and Neural Networks</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://butchland.github.io/butchland-machine-learning-notes/images/j586af7nxvu41.jpg" /><media:content medium="image" url="https://butchland.github.io/butchland-machine-learning-notes/images/j586af7nxvu41.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>